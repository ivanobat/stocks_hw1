---
title: "homework1"
author: "Ivan Aguilar"
date: '2022-05-03'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'C:\\Users\\ivano\\Desktop\\DSMMaster\\MLFin\\')
rm(list=ls())

library(tidyverse)
library(xts)
library(quantmod)
library(TTR)
library(lmtest)
library(dygraphs)
library(kernlab)
library(ggplot2)
library(glmnet)
```

```{r}
# Auxiliary functions
ssr <-function(actual,pred){
  sum((actual - pred)^2)
}
##Normalize Residual Mean Square Error (NRMSE) funct
nrmse <- function(actual,pred){
  sqrt(ssr(actual,pred)/((length(actual)-1)*var(actual)))
} 
##percentage of outperforming direct sample mean (sample expected value)
pcorrect<- function(actual,pred){
  (1-nrmse(actual,pred))*100
}
```


```{r}
data.env = readRDS('.\\HW1\\WorldMarkts99_20.RDS')

names<-c("India", "Brazil","UK","Germany","USA","China-Shanghai",
             "Spain","Indonesia","Mexico","Japan","Taiwan","VLIC","VIX")

markets_codes = ls(data.env)[1:11]
markets_names = names[1:11]
volatilities_codes = ls(data.env)[12:13]
volatilities_names = names[12:13]

```

```{r}
markets = data.frame(matrix(ncol=2, nrow=11))
colnames(markets) = c('name', 'code')
markets$name = markets_names
markets$code = markets_codes
```

```{r warning=FALSE}
mex_market = xts()
mex_market = na.approx(Ad(get('MXX', data.env)))
mex_market = periodReturn(mex_market,period='daily', type='log')

lambda = 0.94
ratio = 1-lambda
n = 1
mex_ema = EMA(mex_market, n=n, ratio=ratio)

mex_sd = sd(mex_market)
ema_sd = sqrt(mean(mex_ema))

print(mex_sd)
print(ema_sd)
```

```{r}
mex_ema_plot = dygraph(data=mex_ema, main='Exponential Moving Average') %>%
  dyRangeSelector() %>%
  dyAxis('x', label = "Date") %>%
  dyAxis('y', axisLabelFormatter='function(v){return (v).toFixed(4)}') %>%
  dyOptions(axisLabelFontSize=10, fillGraph = FALSE, fillAlpha=0.1, drawPoints=FALSE)
  
mex_ema_plot
```

```{r, warning=FALSE}
return_week = list()
return_month = list()
volat_week = list()
volat_month = list()
periods = c('weekly','monthly')

start_date="2017-07-01"
end_date="2019-06-30"

for (period in periods) {
  for (row in 1:nrow(markets)) {
    temp = xts()
    temp = na.approx(Ad(get(markets[row,'code'], data.env)))
    temp = periodReturn(temp, period=period, type='log')
    temp = window(temp, start=start_date, end=end_date)
    ema = EMA(temp, n=n, ratio=ratio)
    
    if (period == 'weekly') {
      return_week[[markets[row,'name']]] = temp
      volat_week[[markets[row,'name']]] = ema
    } else {
      return_month[[markets[row,'name']]] = temp
      volat_month[[markets[row,'name']]] = ema
    }
  }
}
```

```{r, warning=FALSE}
gtest = function(market1, market2, minorder, maxorder){
  test_result = ""
  for (i in minorder:maxorder) {
    caus = grangertest(market1, market2, order=i)
    if (caus$`Pr(>F)`[2]<0.05) {
      test_result = paste0(test_result,"1")
    }
    else{
      test_result = paste0(test_result,"0")
    }
  }
  return(test_result)
}

res_return_week = data.frame(matrix(nrow=11, ncol=11))
colnames(res_return_week) = names(return_week)
rownames(res_return_week) = names(return_week)

res_return_month = data.frame(matrix(nrow=11, ncol=11))
colnames(res_return_month) = names(return_month)
rownames(res_return_month) = names(return_month)

res_volat_week = data.frame(matrix(nrow=11, ncol=11))
colnames(res_volat_week) = names(return_week)
rownames(res_volat_week) = names(return_week)

res_volat_month = data.frame(matrix(nrow=11, ncol=11))
colnames(res_volat_month) = names(return_month)
rownames(res_volat_month) = names(return_month)

for (first_market in names(return_week)){
  for (second_market in names(return_week)){
    if (first_market!=second_market){

      row = nrow(res_return_week)+1

      caus_week = gtest(return_week[[first_market]], return_week[[second_market]],1,4)
      res_return_week[first_market,second_market] = caus_week
      
      caus_month = gtest(return_month[[first_market]], return_month[[second_market]],1,4)
      res_return_month[first_market,second_market] = caus_month
      
      caus_week = gtest(volat_week[[first_market]], volat_week[[second_market]],1,4)
      res_volat_week[first_market,second_market] = caus_week
      
      caus_month = gtest(volat_month[[first_market]], volat_month[[second_market]],1,4)
      res_volat_month[first_market,second_market] = caus_month
      
      }
    }
}
```

```{r}
res_return_week
```

```{r}
res_return_month
```


```{r}
res_volat_week
```


```{r}
res_volat_month
```

```{r}
sp500goyal = as.xts(read.zoo('.\\data\\GoyalMonthly2005.csv', sep=',', header=TRUE, format='%Y-%m-%d'))
data=sp500goyal['1927/2005']
colnames(data)
```

```{r}
tau = 1 #data is monthly. Try tau=12 (year), tau=3 (quarterly)
##1. Target and Feature as plain Price
target = data$Index
target = diff(log(data$Index), diff=tau)
target = na.trim(target-mean(na.omit(target)))

sp500ep = log(data$E12) - log(stats::lag(data$Index,1)) # ep
sp500ep = diff(sp500ep, diff=tau)

sp500dp = log(data$D12) - log(stats::lag(data$Index,1)) # dp
sp500dp = diff(sp500dp, diff=tau)

sp500dy = log(data$D12) - log(stats::lag(data$Index,1)) # dy
sp500dy = diff(sp500dy, diff=tau)

feat = merge(na.trim(stats::lag(target,1)),
             na.trim(stats::lag(target,2)),
             na.trim(stats::lag(target,3)),
             sp500ep,
             na.trim(stats::lag(sp500ep,1)),
             na.trim(stats::lag(sp500ep,2)),
             sp500dp,
             na.trim(stats::lag(sp500dp,1)),
             na.trim(stats::lag(sp500dp,2)),
             sp500dy,
             na.trim(stats::lag(sp500dy,1)),
             na.trim(stats::lag(sp500dy,2)),
             #add other features here,
             all=FALSE)

dataset = merge(feat,target,all=FALSE)

colnames(dataset) = c("lag.1", "lag.2", "lag.3",
                      "ep","ep.1","ep.2",
                      "dp","dp.1","dp.2",
                      "dy","dy.1","dy.2",
                      #names of other features,
                      "TARGET")

```

```{r}
##Divide data into training (75%) and testing (25%). 
T<-nrow(dataset)
p=0.75
T_trn <- round(p*T)
trainindex <- 1:T_trn
##process class sets as data frames
train_data = as.data.frame(dataset[trainindex,])
rownames(train_data) = NULL
test_data = as.data.frame(dataset[-trainindex,])
rownames(test_data) = NULL
```

```{r}
head(dataset)
```


```{r}
gpfit = gausspr(TARGET~., data=train_data,
                type="regression",
                kernel="rbfdot", 
                var = 0.003
)
gpfit

##build predictor (predict on test data)
GPpredict <- predict(gpfit,test_data)

```


```{r}
### Evaluation of Results
actualTS = test_data[,ncol(test_data)] ##the true series to predict
predicTS = GPpredict

res <- list("GP"=pcorrect(actualTS,predicTS))
unlist(res)

train.error <- error(gpfit)  
test.error <- mean((actualTS - predicTS)^2)
gap <- test.error - train.error ; gap

yl=c(min(actualTS,predicTS),max(actualTS,predicTS)) #set y limits
plot(actualTS,predicTS,ylim=yl)

plot(actualTS,t='l',col='gray20', ylab='', xlab ='',lty=3, main='GP predictions', cex.main=0.75)
lines(GPpredict,col='green',lwd=2)
legend('bottomright',legend = c('target','GP'),col=c('gray20','green'),lty=c(3,1),cex=.7)
```

```{r}
x_vars = model.matrix(TARGET~. , dataset)[,-1]
y_var = dataset$TARGET
#lambda_seq = 10^seq(2, -2, by = -.1)

cv_output = cv.glmnet(x_vars, 
                      y_var,
                      alpha = 1, 
                      nfolds = 10)

# identifying best lamda
best_lam <- cv_output$lambda.min
best_lam
```

```{r}
plot(cv_output)
head(x_vars)
```


```{r}
# Rebuilding the model with best lamda value identified
lasso_best <- glmnet(x_vars, y_var, alpha = 1, lambda = best_lam)

coef(lasso_best)
```
```{r}
gpfit = gausspr(TARGET~., data=select(train_data,lag.1,ep.2,TARGET),
                type="regression",
                kernel="rbfdot", 
                #kernel= "rbfdot", #"vanilladot",
                #kernel= ker1,  
                #kpar = list(sigma = 0.4), #list of kernel hyper-parameters for rbf
                ## if you make it constant value then does not make mle estimation of sigma
                #kpar=list(scale=2,offset=2), ##for tanh
                var = 0.003 # the initial noise variance: 0.001 default min value
)
gpfit

##build predictor (predict on test data)
GPpredict <- predict(gpfit,test_data)
```

```{r}
### Evaluation of Results
actualTS = test_data[,ncol(test_data)] ##the true series to predict
predicTS = GPpredict

res <- list("GP"=pcorrect(actualTS,predicTS))
unlist(res)

##Check the gap between training error (mse) and testing error
train.error <- error(gpfit)  
test.error <- mean((actualTS - predicTS)^2)
gap <- test.error - train.error ; gap

##For visual comparison

yl=c(min(actualTS,predicTS),max(actualTS,predicTS)) #set y limits
plot(actualTS,predicTS,ylim=yl)

##Forecasting: PRICE, draw the simulations of price
#par( mfrow = c( 1, 2 ) )
#par(mar=c(2.5,2.5,2.5,2.5))
plot(actualTS,t='l',col='gray20', ylab='', xlab ='',lty=3, main='GP predictions', cex.main=0.75)
lines(GPpredict,col='green',lwd=2)
legend('bottomright',legend = c('target','GP'),col=c('gray20','green'),lty=c(3,1),cex=.7)
```

